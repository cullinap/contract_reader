{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras\n",
    "from keras.utils import np_utils\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from keras.wrappers.scikit_learn import KerasClassifier\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import cross_val_score\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "file exists, loading data...\n",
      "loaded...\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "\n",
    "print('file exists, loading data...')\n",
    "    \n",
    "pkl_file = open('./data/keras-data.pkl', 'rb')\n",
    "d = pickle.load(pkl_file)\n",
    "pkl_file.close()\n",
    "\n",
    "print('loaded...')\n",
    "\n",
    "tfidf_ = d[0]\n",
    "hl = d[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'numpy.ndarray'> (120, 5)\n"
     ]
    }
   ],
   "source": [
    "X=tfidf_.toarray()\n",
    "y = hl\n",
    "\n",
    "print(type(X),X.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "# encode class values as integers\n",
    "encoder = LabelEncoder()\n",
    "encoder.fit(y)\n",
    "encoded_y = encoder.transform(y)\n",
    "# convert integers to dummy variables (i.e. one hot encoded)\n",
    "dummy_y = np_utils.to_categorical(encoded_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline: 90.52% (1.71%)\n"
     ]
    }
   ],
   "source": [
    "# define baseline model\n",
    "def baseline_model():\n",
    "    # create model\n",
    "    model = Sequential()\n",
    "    model.add(Dense(8, input_dim=5, activation='relu'))\n",
    "    model.add(Dropout(0.2))\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(Dense(64))\n",
    "    model.add(Dropout(0.2))\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(Dense(1))\n",
    "    model.add(Dense(8, activation='softmax'))\n",
    "    # Compile model\n",
    "    model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "estimator = KerasClassifier(build_fn=baseline_model, epochs=200, batch_size=5, verbose=0)\n",
    "kfold = KFold(n_splits=10, shuffle=True)\n",
    "results = cross_val_score(estimator, X, dummy_y, cv=kfold)\n",
    "print(\"Baseline: %.2f%% (%.2f%%)\" % (results.mean()*100, results.std()*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Dense(8, input_dim=5, activation='relu'))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dense(64))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dense(1))\n",
    "model.add(Dense(8, activation='softmax'))\n",
    " \n",
    "model.compile(loss='binary_crossentropy',\n",
    "              optimizer='adam',\n",
    "              metrics=['accuracy'])\n",
    " \n",
    "history = model.fit(X, dummy_y,\n",
    "                    batch_size=5,\n",
    "                    epochs=30,\n",
    "                    verbose=0,\n",
    "                    validation_split=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['agreement', 'credit_tips', 'error', 'fee', 'interest', 'payment',\n",
       "       'purchases', 'rate'], dtype=object)"
      ]
     },
     "execution_count": 166,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# score = model.evaluate(X, y_test,\n",
    "#                        batch_size=5, verbose=1)\n",
    " \n",
    "# print('Test accuracy:', score[1])\n",
    " \n",
    "text_labels = encoder.classes_; text_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('./data/bootstrap.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [],
   "source": [
    "loaded_model = keras.models.load_model('./data/bootstrap.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'Sequential' object has no attribute 'texts_to_sequences'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-177-b7682ca91e00>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mtxt\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtfidf__\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0mseq\u001b[0m\u001b[0;34m=\u001b[0m \u001b[0mloaded_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtexts_to_sequences\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtxt\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0mpadded\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpad_sequences\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mseq\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmaxlen\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmax_len\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0mpred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict_classes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpadded\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'Sequential' object has no attribute 'texts_to_sequences'"
     ]
    }
   ],
   "source": [
    "from keras.preprocessing.sequence import pad_sequences\n",
    "maxlen = 100\n",
    "\n",
    "txt=tfidf__\n",
    "seq= loaded_model.texts_to_sequences([txt])\n",
    "padded = pad_sequences(seq, maxlen=max_len)\n",
    "pred = model.predict_classes(padded)\n",
    "print(pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gensim\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem.snowball import SnowballStemmer\n",
    "from nltk import bigrams,trigrams\n",
    "\n",
    "def preprocess(text, **kwargs):\n",
    "        '''\n",
    "        Basic NLP preprocessor\n",
    "        -removes stop words\n",
    "        -n-grams\n",
    "        -stem\n",
    "        -simple gensim preprocessor\n",
    "        '''\n",
    "\n",
    "        stopwords_ = kwargs.get('stopwords')\n",
    "        #cust_sw = kwargs.get('custom_sw')\n",
    "        stemmer = kwargs.get('stemmer')\n",
    "        ngrams = kwargs.get('ngrams')\n",
    "\n",
    "        text = text.apply(gensim.utils.simple_preprocess, min_len=3)\n",
    "        \n",
    "        sw = set(stopwords.words(stopwords_))\n",
    "        #custom_sw = set(cust_sw)\n",
    "\n",
    "        if stopwords_: text = text.apply(lambda s: [w for w in s if w not in sw]) \n",
    "\n",
    "        #if custom_sw: text = text.apply(lambda s: [w for w in s if w not in custom_sw])\n",
    "\n",
    "        if stemmer=='yes': text = text.apply(lambda s: [SnowballStemmer(\"english\", ignore_stopwords=True).stem(w) for w in s])\n",
    "\n",
    "        if ngrams=='bigrams': \n",
    "            text = text.apply(lambda s: ['_'.join(x) for x in nltk.bigrams(s)] + s)\n",
    "\n",
    "        elif ngrams=='trigrams':\n",
    "            text = text.apply(lambda s: ['_'.join(x) for x in nltk.trigrams(s)] + s)\n",
    "\n",
    "        return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = 'This APR will vary with the market based on the Prime Rate.'\n",
    "\n",
    "\n",
    "process_val = {'stopwords':'english',\n",
    "               'stemmer':'yes',\n",
    "               'custom_stopwords': ['pat'],\n",
    "               'ngrams':'bigrams'}\n",
    "\n",
    "test = preprocess(pd.Series(text), **process_val).apply(lambda x:', '.join(map(str, x)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf = TfidfVectorizer()\n",
    "\n",
    "tfidf__ = tfidf.fit_transform(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 108 samples, validate on 12 samples\n",
      "Epoch 1/30\n",
      "108/108 [==============================] - 3s 27ms/step - loss: 0.3801 - acc: 0.8750 - val_loss: 0.3767 - val_acc: 0.8750\n",
      "Epoch 2/30\n",
      "108/108 [==============================] - 0s 113us/step - loss: 0.3779 - acc: 0.8750 - val_loss: 0.3785 - val_acc: 0.8750\n",
      "Epoch 3/30\n",
      "108/108 [==============================] - 0s 144us/step - loss: 0.3755 - acc: 0.8750 - val_loss: 0.3802 - val_acc: 0.8750\n",
      "Epoch 4/30\n",
      "108/108 [==============================] - 0s 193us/step - loss: 0.3746 - acc: 0.8750 - val_loss: 0.3818 - val_acc: 0.8750\n",
      "Epoch 5/30\n",
      "108/108 [==============================] - 0s 192us/step - loss: 0.3749 - acc: 0.8750 - val_loss: 0.3836 - val_acc: 0.8750\n",
      "Epoch 6/30\n",
      "108/108 [==============================] - 0s 185us/step - loss: 0.3746 - acc: 0.8750 - val_loss: 0.3851 - val_acc: 0.8750\n",
      "Epoch 7/30\n",
      "108/108 [==============================] - 0s 194us/step - loss: 0.3723 - acc: 0.8750 - val_loss: 0.3864 - val_acc: 0.8750\n",
      "Epoch 8/30\n",
      "108/108 [==============================] - 0s 162us/step - loss: 0.3729 - acc: 0.8750 - val_loss: 0.3878 - val_acc: 0.8750\n",
      "Epoch 9/30\n",
      "108/108 [==============================] - 0s 213us/step - loss: 0.3699 - acc: 0.8750 - val_loss: 0.3887 - val_acc: 0.8750\n",
      "Epoch 10/30\n",
      "108/108 [==============================] - 0s 182us/step - loss: 0.3707 - acc: 0.8750 - val_loss: 0.3894 - val_acc: 0.8750\n",
      "Epoch 11/30\n",
      "108/108 [==============================] - 0s 151us/step - loss: 0.3694 - acc: 0.8750 - val_loss: 0.3902 - val_acc: 0.8750\n",
      "Epoch 12/30\n",
      "108/108 [==============================] - 0s 232us/step - loss: 0.3677 - acc: 0.8750 - val_loss: 0.3909 - val_acc: 0.8750\n",
      "Epoch 13/30\n",
      "108/108 [==============================] - 0s 141us/step - loss: 0.3681 - acc: 0.8750 - val_loss: 0.3916 - val_acc: 0.8750\n",
      "Epoch 14/30\n",
      "108/108 [==============================] - 0s 264us/step - loss: 0.3680 - acc: 0.8750 - val_loss: 0.3922 - val_acc: 0.8750\n",
      "Epoch 15/30\n",
      "108/108 [==============================] - 0s 152us/step - loss: 0.3658 - acc: 0.8750 - val_loss: 0.3930 - val_acc: 0.8750\n",
      "Epoch 16/30\n",
      "108/108 [==============================] - 0s 234us/step - loss: 0.3666 - acc: 0.8750 - val_loss: 0.3936 - val_acc: 0.8750\n",
      "Epoch 17/30\n",
      "108/108 [==============================] - 0s 193us/step - loss: 0.3652 - acc: 0.8750 - val_loss: 0.3945 - val_acc: 0.8750\n",
      "Epoch 18/30\n",
      "108/108 [==============================] - 0s 221us/step - loss: 0.3649 - acc: 0.8750 - val_loss: 0.3949 - val_acc: 0.8750\n",
      "Epoch 19/30\n",
      "108/108 [==============================] - 0s 193us/step - loss: 0.3639 - acc: 0.8750 - val_loss: 0.3955 - val_acc: 0.8750\n",
      "Epoch 20/30\n",
      "108/108 [==============================] - 0s 235us/step - loss: 0.3623 - acc: 0.8750 - val_loss: 0.3960 - val_acc: 0.8750\n",
      "Epoch 21/30\n",
      "108/108 [==============================] - 0s 201us/step - loss: 0.3625 - acc: 0.8750 - val_loss: 0.3963 - val_acc: 0.8750\n",
      "Epoch 22/30\n",
      "108/108 [==============================] - 0s 245us/step - loss: 0.3595 - acc: 0.8750 - val_loss: 0.3967 - val_acc: 0.8750\n",
      "Epoch 23/30\n",
      "108/108 [==============================] - 0s 186us/step - loss: 0.3610 - acc: 0.8750 - val_loss: 0.3970 - val_acc: 0.8750\n",
      "Epoch 24/30\n",
      "108/108 [==============================] - 0s 195us/step - loss: 0.3589 - acc: 0.8750 - val_loss: 0.3974 - val_acc: 0.8750\n",
      "Epoch 25/30\n",
      "108/108 [==============================] - 0s 220us/step - loss: 0.3581 - acc: 0.8750 - val_loss: 0.3979 - val_acc: 0.8750\n",
      "Epoch 26/30\n",
      "108/108 [==============================] - 0s 199us/step - loss: 0.3594 - acc: 0.8750 - val_loss: 0.3982 - val_acc: 0.8750\n",
      "Epoch 27/30\n",
      "108/108 [==============================] - 0s 209us/step - loss: 0.3551 - acc: 0.8750 - val_loss: 0.3985 - val_acc: 0.8750\n",
      "Epoch 28/30\n",
      "108/108 [==============================] - 0s 237us/step - loss: 0.3568 - acc: 0.8750 - val_loss: 0.3987 - val_acc: 0.8750\n",
      "Epoch 29/30\n",
      "108/108 [==============================] - 0s 154us/step - loss: 0.3562 - acc: 0.8750 - val_loss: 0.3988 - val_acc: 0.8750\n",
      "Epoch 30/30\n",
      "108/108 [==============================] - 0s 182us/step - loss: 0.3544 - acc: 0.8750 - val_loss: 0.3991 - val_acc: 0.8750\n"
     ]
    }
   ],
   "source": [
    "history = estimator.fit(X, dummy_y,\n",
    "                    batch_size=batch_size,\n",
    "                    epochs=30,\n",
    "                    verbose=1,\n",
    "                    validation_split=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(<11x1 sparse matrix of type '<class 'numpy.float64'>'\n",
       "\twith 11 stored elements in COOrdinate format>, dtype=object)"
      ]
     },
     "execution_count": 199,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.array(tfidf__.reshape(11,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "cannot reshape array of size 11 into shape (11, 2)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-195-02cc967a3ff9>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtfidf__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m11\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/usr/local/lib/python3.7/site-packages/scipy/sparse/base.py\u001b[0m in \u001b[0;36mreshape\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    121\u001b[0m         \u001b[0;31m# If the shape already matches, don't bother doing an actual reshape\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    122\u001b[0m         \u001b[0;31m# Otherwise, the default is to convert to COO and use its reshape\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 123\u001b[0;31m         \u001b[0mshape\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcheck_shape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    124\u001b[0m         \u001b[0morder\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcheck_reshape_kwargs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    125\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mshape\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/site-packages/scipy/sparse/sputils.py\u001b[0m in \u001b[0;36mcheck_shape\u001b[0;34m(args, current_shape)\u001b[0m\n\u001b[1;32m    295\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mnew_size\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mcurrent_size\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    296\u001b[0m                 raise ValueError('cannot reshape array of size {} into shape {}'\n\u001b[0;32m--> 297\u001b[0;31m                                  .format(current_size, new_shape))\n\u001b[0m\u001b[1;32m    298\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnegative_indexes\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    299\u001b[0m             \u001b[0mskip\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnegative_indexes\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: cannot reshape array of size 11 into shape (11, 2)"
     ]
    }
   ],
   "source": [
    "model.predict(np.array(tfidf__.reshape(11,2)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
